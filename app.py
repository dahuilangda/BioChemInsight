import os
import sys
import json
import pandas as pd
import gradio as gr
from pathlib import Path
import tempfile
import shutil
from typing import List

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥æœ¬åœ°æ¨¡å—
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# æŠ‘åˆ¶ä¸å¿…è¦çš„è­¦å‘Šä¿¡æ¯
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
import warnings
warnings.filterwarnings("ignore")

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from pipeline import get_total_pages
from structure_parser import extract_structures_from_pdf
from activity_parser import extract_activity_data
import json

class BioChemInsightApp:
    """å°è£…BioChemInsightåº”ç”¨çš„æ ¸å¿ƒé€»è¾‘å’ŒUI"""
    def __init__(self):
        """åˆå§‹åŒ–åº”ç”¨ï¼Œåˆ›å»ºä¸´æ—¶ç›®å½•"""
        self.temp_dir = tempfile.mkdtemp()
        self.current_pdf_path = None

    def get_pdf_info(self, pdf_file):
        """å½“ç”¨æˆ·ä¸Šä¼ PDFåï¼Œè·å–åŸºæœ¬ä¿¡æ¯"""
        if pdf_file is None:
            return "âŒ è¯·å…ˆä¸Šä¼ ä¸€ä¸ªPDFæ–‡ä»¶", 0
        try:
            # å°†ä¸Šä¼ çš„æ–‡ä»¶ä¿å­˜åˆ°ä¸´æ—¶ç›®å½•ï¼Œä»¥ä¾¿åç»­å¤„ç†
            self.current_pdf_path = os.path.join(self.temp_dir, "uploaded.pdf")
            shutil.copy(pdf_file.name, self.current_pdf_path)
            total_pages = get_total_pages(self.current_pdf_path)
            info = f"âœ… PDFä¸Šä¼ æˆåŠŸï¼Œå…± {total_pages} é¡µ"
            return info, total_pages
        except Exception as e:
            return f"âŒ PDFåŠ è½½å¤±è´¥: {str(e)}", 0

    def parse_pages_input(self, pages_str):
        """è§£æé¡µé¢è¾“å…¥å­—ç¬¦ä¸²ï¼Œæ”¯æŒ '1,3,5-7,10' æ ¼å¼
        è¿”å›é¡µé¢ç¼–å·åˆ—è¡¨
        """
        if not pages_str or not pages_str.strip():
            return []
        
        pages = []
        parts = pages_str.strip().split(',')
        
        for part in parts:
            part = part.strip()
            if not part:
                continue
                
            if '-' in part:
                # å¤„ç†èŒƒå›´ "5-7"
                try:
                    start, end = map(int, part.split('-', 1))
                    pages.extend(range(start, end + 1))
                except ValueError:
                    continue
            else:
                # å¤„ç†å•ä¸ªé¡µé¢
                try:
                    pages.append(int(part))
                except ValueError:
                    continue
        
        # å»é‡å¹¶æ’åº
        return sorted(list(set(pages)))
    
    def _generate_pdf_gallery(self, start_page, pages_per_view, total_pages):
        """ç”Ÿæˆå¯äº¤äº’çš„PDFé¡µé¢é¢„è§ˆç”»å»Š"""
        if not self.current_pdf_path or not os.path.exists(self.current_pdf_path):
            return "<div class='center-placeholder'>è¯·å…ˆä¸Šä¼ æœ‰æ•ˆçš„PDFæ–‡ä»¶</div>"
        
        try:
            import fitz  # PyMuPDF
            doc = fitz.open(self.current_pdf_path)
            
            start_page = max(1, min(start_page, total_pages))
            end_page = min(start_page + pages_per_view - 1, total_pages)
            pages_to_show = list(range(start_page, end_page + 1))
            
            # ç®€åŒ–çš„HTMLç”»å»Šï¼Œä¸ä½¿ç”¨JavaScript
            gallery_html = f"""
            <div class="gallery-wrapper">
                <div id="selection-info" class="selection-info-bar">
                    <span style="font-weight: 500;">æç¤º: è¯·ä½¿ç”¨ä¸‹æ–¹çš„é¡µé¢é€‰æ‹©å·¥å…·æ¥é€‰æ‹©è¦å¤„ç†çš„é¡µé¢</span>
                </div>
                <div id="gallery-container" class="gallery-container">
            """
            
            for page_num in pages_to_show:
                page = doc[page_num - 1]
                pix = page.get_pixmap(matrix=fitz.Matrix(1.5, 1.5))
                img_data = pix.tobytes("png")
                import base64
                img_base64 = base64.b64encode(img_data).decode()
                
                gallery_html += f"""
                <div class="page-item" data-page="{page_num}">
                    <img src='data:image/png;base64,{img_base64}' alt='Page {page_num}' />
                    <div class="page-label">Page {page_num}</div>
                </div>
                """
            
            gallery_html += """
                </div>
            </div>
            """
            doc.close()
            return gallery_html
        except Exception as e:
            return f"<div class='center-placeholder error'>ç”Ÿæˆé¢„è§ˆå¤±è´¥: {str(e)}</div>"

    def update_gallery_view(self, page_input, total_pages):
        """æ ¹æ®ç”¨æˆ·è¾“å…¥æ›´æ–°ç”»å»Šè§†å›¾"""
        if not self.current_pdf_path:
            return "<div class='center-placeholder'>è¯·å…ˆä¸Šä¼ PDFæ–‡ä»¶</div>"
        try:
            start_page = int(page_input)
            pages_per_view = 12  # æ¯é¡µæ˜¾ç¤º12ä¸ªé¢„è§ˆ
            return self._generate_pdf_gallery(start_page, pages_per_view, total_pages)
        except (ValueError, TypeError):
            return self._generate_pdf_gallery(1, 12, total_pages)
        except Exception as e:
            return f"<div class='center-placeholder error'>æ›´æ–°è§†å›¾å¤±è´¥: {str(e)}</div>"

    def extract_structures_only(self, pdf_file, pages_input):
        """ä»…æå–åŒ–å­¦ç»“æ„"""
        if not self.current_pdf_path:
            return "âŒ è¯·å…ˆä¸Šä¼ PDFæ–‡ä»¶", "", None
        
        try:
            # è§£æé¡µé¢è¾“å…¥
            page_nums = self.parse_pages_input(pages_input)
            if not page_nums:
                return "âŒ è¯·è¾“å…¥è¦å¤„ç†çš„é¡µé¢ï¼Œä¾‹å¦‚: 1,3,5-7,10", "", None
            
            output_dir = os.path.join(self.temp_dir, "structures_output")
            os.makedirs(output_dir, exist_ok=True)
            
            all_structures = []
            
            # å¤„ç†ä¸è¿ç»­é¡µé¢ï¼šå°†é¡µé¢åˆ†ç»„ä¸ºè¿ç»­çš„åŒºé—´
            page_nums.sort()
            groups = []
            current_group = [page_nums[0]]
            
            for i in range(1, len(page_nums)):
                if page_nums[i] == page_nums[i-1] + 1:  # è¿ç»­é¡µé¢
                    current_group.append(page_nums[i])
                else:  # ä¸è¿ç»­ï¼Œå¼€å§‹æ–°ç»„
                    groups.append(current_group)
                    current_group = [page_nums[i]]
            groups.append(current_group)
            
            # å¤„ç†æ¯ç»„è¿ç»­é¡µé¢
            for group_idx, group in enumerate(groups):
                start_page = min(group)
                end_page = max(group)
                
                # ä¸ºæ¯ç»„åˆ›å»ºå­ç›®å½•
                group_output_dir = os.path.join(output_dir, f"group_{group_idx}")
                os.makedirs(group_output_dir, exist_ok=True)
                
                structures = extract_structures_from_pdf(
                    pdf_file=self.current_pdf_path,
                    page_start=start_page,
                    page_end=end_page,
                    output=group_output_dir,
                    engine='molnextr'
                )
                
                if structures:
                    # ä¸ºæ¯ä¸ªç»“æ„æ·»åŠ é¡µé¢ä¿¡æ¯
                    for structure in structures:
                        if isinstance(structure, dict):
                            structure['source_pages'] = list(group)
                        all_structures.extend([structure] if not isinstance(structure, list) else structure)
            
            if all_structures:
                # å»é‡ï¼šå¦‚æœæœ‰é‡å¤çš„SMILESï¼Œåªä¿ç•™ä¸€ä¸ª
                seen_smiles = set()
                unique_structures = []
                for structure in all_structures:
                    smiles = structure.get('SMILES', '') if isinstance(structure, dict) else str(structure)
                    if smiles and smiles not in seen_smiles:
                        seen_smiles.add(smiles)
                        unique_structures.append(structure)
                
                if unique_structures:
                    df = pd.DataFrame(unique_structures)
                    page_ranges = self._format_page_ranges(page_nums)
                    return f"âœ… æˆåŠŸä»é¡µé¢ {page_ranges} æå– {len(df)} ä¸ªåŒ–å­¦ç»“æ„", df.to_html(classes="result-table", index=False), unique_structures
                else:
                    page_ranges = self._format_page_ranges(page_nums)
                    return f"âš ï¸ åœ¨é¡µé¢ {page_ranges} æœªæ‰¾åˆ°åŒ–å­¦ç»“æ„", "", None
            else:
                return "âŒ ç»“æ„æå–å¤±è´¥", "", None
        except Exception as e:
            return f"âŒ å‘ç”Ÿæ„å¤–é”™è¯¯: {str(e)}", "", None

    def _format_page_ranges(self, page_nums):
        """å°†é¡µé¢åˆ—è¡¨æ ¼å¼åŒ–ä¸ºå‹å¥½çš„èŒƒå›´æ˜¾ç¤º"""
        if not page_nums:
            return ""
        
        page_nums.sort()
        ranges = []
        start = page_nums[0]
        end = page_nums[0]
        
        for i in range(1, len(page_nums)):
            if page_nums[i] == end + 1:
                end = page_nums[i]
            else:
                if start == end:
                    ranges.append(str(start))
                else:
                    ranges.append(f"{start}-{end}")
                start = end = page_nums[i]
        
        if start == end:
            ranges.append(str(start))
        else:
            ranges.append(f"{start}-{end}")
        
        return ", ".join(ranges)

    def extract_assay_only(self, pdf_file, pages_input, structures_data):
        """ä»…æå–ç”Ÿç‰©æ´»æ€§æ•°æ®ï¼ˆä¾èµ–äºå·²æå–çš„ç»“æ„ï¼‰"""
        if not self.current_pdf_path:
            return "âŒ è¯·å…ˆä¸Šä¼ PDFæ–‡ä»¶", "", None
        
        # è§£æé¡µé¢è¾“å…¥
        page_nums = self.parse_pages_input(pages_input)
        if not page_nums:
            return "âŒ è¯·è¾“å…¥è¦å¤„ç†çš„é¡µé¢ï¼Œä¾‹å¦‚: 1,3,5-7,10", "", None
        
        if not structures_data:
            return "âš ï¸ å¿…é¡»å…ˆæˆåŠŸæå–åŒ–å­¦ç»“æ„", "", None
        
        try:
            output_dir = os.path.join(self.temp_dir, "assay_output")
            os.makedirs(output_dir, exist_ok=True)
            
            # æ„å»ºåŒ–åˆç‰©IDåˆ—è¡¨
            if isinstance(structures_data[0], dict):
                compound_id_list = [row.get('COMPOUND_ID', row.get('SMILES', '')) for row in structures_data]
            else:
                compound_id_list = structures_data
            
            all_assay_data = {}
            
            # å¤„ç†ä¸è¿ç»­é¡µé¢ï¼šå°†é¡µé¢åˆ†ç»„ä¸ºè¿ç»­çš„åŒºé—´
            page_nums.sort()
            groups = []
            current_group = [page_nums[0]]
            
            for i in range(1, len(page_nums)):
                if page_nums[i] == page_nums[i-1] + 1:  # è¿ç»­é¡µé¢
                    current_group.append(page_nums[i])
                else:  # ä¸è¿ç»­ï¼Œå¼€å§‹æ–°ç»„
                    groups.append(current_group)
                    current_group = [page_nums[i]]
            groups.append(current_group)
            
            # å¤„ç†æ¯ç»„è¿ç»­é¡µé¢
            for group_idx, group in enumerate(groups):
                start_page = min(group)
                end_page = max(group)
                
                assay_dict = extract_activity_data(
                    pdf_file=self.current_pdf_path,
                    assay_page_start=[start_page],
                    assay_page_end=[end_page], 
                    assay_name=f"Bioactivity_Assay_Group_{group_idx}",
                    compound_id_list=compound_id_list,
                    output_dir=output_dir,
                    lang='en'
                )
                
                if assay_dict:
                    all_assay_data.update(assay_dict)
            
            if all_assay_data:
                data = {"Bioactivity_Assay": all_assay_data}
                html = ""
                for name, items in data.items():
                    html += f"<h4>{name}</h4>"
                    if items:
                        df = pd.DataFrame(list(items.items()), columns=['Compound_ID', 'Activity'])
                        html += df.to_html(classes="result-table", index=False)
                
                page_ranges = self._format_page_ranges(page_nums)
                return f"âœ… æˆåŠŸä»é¡µé¢ {page_ranges} æå–æ´»æ€§æ•°æ®ï¼ŒåŒ…å« {len(all_assay_data)} ä¸ªåŒ–åˆç‰©", html, data
            else:
                page_ranges = self._format_page_ranges(page_nums)
                return f"âš ï¸ åœ¨é¡µé¢ {page_ranges} æœªæ‰¾åˆ°ç”Ÿç‰©æ´»æ€§æ•°æ®", "", None
        except Exception as e:
            return f"âŒ å‘ç”Ÿæ„å¤–é”™è¯¯: {str(e)}", "", None

    def extract_both(self, pages_input):
        """åŒæ—¶æå–ç»“æ„å’Œæ´»æ€§æ•°æ®ï¼Œå¹¶è¿›è¡Œåˆå¹¶"""
        s_stat, s_html, s_data = self.extract_structures_only(None, pages_input)
        if not s_data:
            return s_stat, s_html, "ç»“æ„æå–å¤±è´¥ï¼Œæ— æ³•ç»§ç»­", "", "åˆå¹¶å¤±è´¥", None, None, None

        a_stat, a_html, a_data = self.extract_assay_only(None, pages_input, s_data)

        m_path, m_stat = None, "æ— éœ€åˆå¹¶"
        if s_data and a_data:
            try:
                # ç®€å•çš„æ•°æ®åˆå¹¶é€»è¾‘
                merged_data = []
                for s_item in s_data:
                    compound_id = s_item.get('COMPOUND_ID', s_item.get('SMILES', ''))
                    merged_item = s_item.copy()
                    
                    # æŸ¥æ‰¾å¯¹åº”çš„æ´»æ€§æ•°æ®
                    for assay_name, assay_dict in a_data.items():
                        if compound_id in assay_dict:
                            merged_item[assay_name] = assay_dict[compound_id]
                    
                    merged_data.append(merged_item)
                
                if merged_data:
                    df = pd.DataFrame(merged_data)
                    path = os.path.join(self.temp_dir, "merged.csv")
                    df.to_csv(path, index=False, encoding='utf-8-sig')
                    m_path = path
                    m_stat = f"âœ… åˆå¹¶æˆåŠŸï¼Œç”Ÿæˆ {len(df)} æ¡è®°å½•"
                else:
                    m_stat = "âš ï¸ åˆå¹¶æˆåŠŸï¼Œä½†æ— åŒ¹é…æ•°æ®"
            except Exception as e:
                m_stat = f"âŒ åˆå¹¶æ—¶å‘ç”Ÿé”™è¯¯: {e}"

        return s_stat, s_html, a_stat, a_html, m_stat, s_data, a_data, m_path

    def download_file(self, data, file_type, filename):
        """æ ¹æ®æ•°æ®ç”Ÿæˆå¯ä¾›ä¸‹è½½çš„æ–‡ä»¶"""
        if not data: return None
        try:
            path = os.path.join(self.temp_dir, filename)
            if file_type == 'csv':
                pd.DataFrame(data).to_csv(path, index=False, encoding='utf-8-sig')
            elif file_type == 'json':
                with open(path, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
            return path
        except Exception:
            return None

    def create_interface(self):
        """åˆ›å»ºå¹¶è¿”å›Gradioç•Œé¢"""
        css = """
        .center-placeholder { text-align: center; padding: 50px; border: 2px dashed #ccc; border-radius: 10px; margin-top: 20px; }
        .error { color: red; }
        .gallery-wrapper { background: #f0f2f5; border-radius: 12px; padding: 16px; }
        .selection-info-bar { text-align: center; margin-bottom: 12px; padding: 8px; background: #e8f4fd; border-radius: 8px; }
        .clear-btn { margin-left: 15px; background: #ffc107; color: black; border: none; padding: 4px 10px; border-radius: 5px; cursor: pointer; }
        .gallery-container { display: grid; grid-template-columns: repeat(auto-fill, minmax(200px, 1fr)); gap: 16px; max-height: 70vh; overflow-y: auto; padding: 5px; }
        .page-item { border: 2px solid #ddd; border-radius: 8px; cursor: pointer; transition: all 0.2s ease; position: relative; background: white; overflow: hidden; }
        .page-item:hover { border-color: #007bff; }
        .page-item.selected { border-color: #28a745; box-shadow: 0 0 10px rgba(40, 167, 69, 0.5); }
        .page-item .selection-check { position: absolute; top: 5px; right: 5px; width: 24px; height: 24px; border-radius: 50%; background: #28a745; color: white; display: none; align-items: center; justify-content: center; font-size: 16px; font-weight: bold; z-index: 2; }
        .page-item.selected .selection-check { display: flex; }
        .page-item img { width: 100%; height: auto; display: block; }
        .page-item .page-label { padding: 8px; font-size: 13px; font-weight: 500; color: #333; background: #f8f9fa; }
        .result-table { width: 100%; border-collapse: collapse; }
        .result-table th, .result-table td { border: 1px solid #ddd; padding: 8px; text-align: left; }
        .result-table th { background-color: #f2f2f2; }
        """
        with gr.Blocks(theme=gr.themes.Soft(primary_hue="blue"), title="BioChemInsight", css=css) as interface:
            # JavaScriptå‡½æ•°å®šä¹‰ - æ”¾åœ¨æœ€é¡¶éƒ¨ç¡®ä¿ä¼˜å…ˆåŠ è½½
            gr.Markdown("<h1>ğŸ§¬ BioChemInsight: æ™ºèƒ½ç”Ÿç‰©åŒ–å­¦æ–‡çŒ®æ•°æ®æå–</h1>")
            
            # çŠ¶æ€å˜é‡
            total_pages, current_page, structures_data, assay_data, merged_path = (
                gr.State(0), gr.State(1), gr.State(None), gr.State(None), gr.State(None)
            )

            with gr.Row():
                with gr.Column(scale=1):
                    pdf_input = gr.File(label="ä¸Šä¼ PDFæ–‡ä»¶", file_types=[".pdf"])
                    pdf_info = gr.Textbox(label="æ–‡æ¡£ä¿¡æ¯", interactive=False)
                    
                    with gr.Group():
                        gr.Markdown("<h4>é¡µé¢å¯¼èˆª</h4>")
                        with gr.Row():
                            prev_btn = gr.Button("â¬…ï¸ ä¸Šä¸€é¡µ")
                            next_btn = gr.Button("â¡ï¸ ä¸‹ä¸€é¡µ")
                        page_input = gr.Number(label="è·³è½¬åˆ°", value=1, precision=0)
                        go_btn = gr.Button("è·³è½¬", variant="primary")

                    with gr.Group():
                        gr.Markdown("<h4>é¡µé¢é€‰æ‹©</h4>")
                        pages_input = gr.Textbox(
                            label="è¦å¤„ç†çš„é¡µé¢", 
                            placeholder="ä¾‹å¦‚: 1,3,5-7,10 (æ”¯æŒå•é¡µé¢ã€èŒƒå›´ã€æ··åˆ)",
                            info="è¾“å…¥é¡µé¢ç¼–å·ï¼Œæ”¯æŒé€—å·åˆ†éš”å’Œè¿å­—ç¬¦èŒƒå›´"
                        )
                    
                    with gr.Group():
                        gr.Markdown("<h4>æå–æ“ä½œ</h4>")
                        struct_btn = gr.Button("ğŸ§ª ä»…æå–ç»“æ„")
                        assay_btn = gr.Button("ğŸ“Š ä»…æå–æ´»æ€§")
                        both_btn = gr.Button("ğŸš€ å…¨éƒ¨æå–å¹¶åˆå¹¶", variant="primary")

                with gr.Column(scale=3):
                    gallery = gr.HTML("<div class='center-placeholder'>ä¸Šä¼ PDFåï¼Œæ­¤å¤„å°†æ˜¾ç¤ºé¡µé¢é¢„è§ˆ</div>")

            with gr.Tabs():
                with gr.TabItem("åŒ–å­¦ç»“æ„"):
                    struct_stat = gr.Textbox(label="çŠ¶æ€", interactive=False)
                    struct_disp = gr.HTML()
                    struct_dl_btn = gr.Button("ä¸‹è½½ç»“æ„ (CSV)", visible=False)
                with gr.TabItem("ç”Ÿç‰©æ´»æ€§"):
                    assay_stat = gr.Textbox(label="çŠ¶æ€", interactive=False)
                    assay_disp = gr.HTML()
                    assay_dl_btn = gr.Button("ä¸‹è½½æ´»æ€§ (JSON)", visible=False)
                with gr.TabItem("åˆå¹¶ç»“æœ"):
                    merged_stat = gr.Textbox(label="çŠ¶æ€", interactive=False)
                    merged_dl_btn = gr.Button("ä¸‹è½½åˆå¹¶æ•°æ® (CSV)", visible=False)

            # éšè—çš„æ–‡ä»¶ç»„ä»¶ç”¨äºè§¦å‘ä¸‹è½½
            dl_struct, dl_assay, dl_merged = gr.File(visible=False), gr.File(visible=False), gr.File(visible=False)

            # --- äº‹ä»¶å¤„ç†é€»è¾‘ ---
            def on_upload(pdf):
                info, pages = self.get_pdf_info(pdf)
                gallery_html = self.update_gallery_view(1, pages)
                return info, pages, 1, gallery_html, None, None, None, gr.update(visible=False), gr.update(visible=False), gr.update(visible=False)
            pdf_input.upload(on_upload, [pdf_input], [pdf_info, total_pages, current_page, gallery, structures_data, assay_data, merged_path, struct_dl_btn, assay_dl_btn, merged_dl_btn])

            def handle_nav(page, pages):
                html = self.update_gallery_view(page, pages)
                return page, html
            go_btn.click(handle_nav, [page_input, total_pages], [current_page, gallery])
            prev_btn.click(lambda c, t: handle_nav(max(1, c - 12), t), [current_page, total_pages], [current_page, gallery])
            next_btn.click(lambda c, t: handle_nav(min(t, c + 12), t), [current_page, total_pages], [current_page, gallery])

            def run_struct_extract(pdf, pages_input):
                stat, html, data = self.extract_structures_only(pdf, pages_input)
                return stat, html, data, gr.update(visible=bool(data))
            struct_btn.click(run_struct_extract, inputs=[pdf_input, pages_input], outputs=[struct_stat, struct_disp, structures_data, struct_dl_btn])

            def run_assay_extract(pdf, pages_input, s_data):
                stat, html, data = self.extract_assay_only(pdf, pages_input, s_data)
                return stat, html, data, gr.update(visible=bool(data))
            assay_btn.click(run_assay_extract, inputs=[pdf_input, pages_input, structures_data], outputs=[assay_stat, assay_disp, assay_data, assay_dl_btn])

            def run_both_extract(pages_input):
                s_stat, s_html, a_stat, a_html, m_stat, s_data, a_data, m_path = self.extract_both(pages_input)
                return s_stat, s_html, a_stat, a_html, m_stat, s_data, a_data, m_path, gr.update(visible=bool(s_data)), gr.update(visible=bool(a_data)), gr.update(visible=bool(m_path))
            both_btn.click(run_both_extract, inputs=[pages_input], outputs=[struct_stat, struct_disp, assay_stat, assay_disp, merged_stat, structures_data, assay_data, merged_path, struct_dl_btn, assay_dl_btn, merged_dl_btn])

            struct_dl_btn.click(lambda d: self.download_file(d, 'csv', 'structures.csv'), [structures_data], [dl_struct])
            assay_dl_btn.click(lambda d: self.download_file(d, 'json', 'assay_data.json'), [assay_data], [dl_assay])
            merged_dl_btn.click(lambda p: p, [merged_path], [dl_merged])
            
        return interface

    def __del__(self):
        """åœ¨åº”ç”¨å…³é—­æ—¶æ¸…ç†ä¸´æ—¶ç›®å½•"""
        try:
            if os.path.exists(self.temp_dir):
                shutil.rmtree(self.temp_dir)
        except Exception as e:
            print(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°ï¼Œå¯åŠ¨Gradioåº”ç”¨"""
    app = BioChemInsightApp()
    interface = app.create_interface()
    interface.launch(server_name="127.0.0.1", server_port=7860, share=False, debug=True)

if __name__ == "__main__":
    main()
